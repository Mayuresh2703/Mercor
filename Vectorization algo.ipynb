{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1dd7b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openai in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (0.27.6)\n",
      "Requirement already satisfied: requests>=2.20 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (2.27.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (4.65.0)\n",
      "Requirement already satisfied: aiohttp in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from openai) (3.8.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (1.24.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.20->openai) (2.8)\n",
      "Requirement already satisfied: attrs>=17.3.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (21.4.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.9.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from aiohttp->openai) (1.3.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from tqdm->openai) (0.4.4)\n"
     ]
    }
   ],
   "source": [
    "pip install openai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7e31aa07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (3.8.1)\n",
      "Requirement already satisfied: click in c:\\users\\athar\\appdata\\roaming\\python\\python310\\site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: joblib in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (1.1.0)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (2022.4.24)\n",
      "Requirement already satisfied: tqdm in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from nltk) (4.65.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec55cbe8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\athar\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Tokenize the text\n",
    "    tokens = word_tokenize(text.lower())\n",
    "\n",
    "    # Remove stop words and punctuation\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in stop_words and token.isalpha()]\n",
    "\n",
    "    # Lemmatize the words\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "\n",
    "    # Join the tokens back into a string\n",
    "    text = ' '.join(tokens)\n",
    "\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be616ffe",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\athar\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\serialization.py:975: UserWarning: Failed to initialize NumPy: module compiled against API version 0x10 but this version of numpy is 0xf . Check the section C-API incompatibility at the Troubleshooting ImportError section at https://numpy.org/devdocs/user/troubleshooting-importerror.html#c-api-incompatibility for indications on how to solve this problem . (Triggered internally at ..\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  obj = cast(Storage, torch.UntypedStorage(nbytes))\n",
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.bias', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "\n",
    "model_name = 'bert-base-uncased'\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModel.from_pretrained(model_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "51688fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = 'This is an example sentence.'\n",
    "input_ids = tokenizer.encode(input_text, add_special_tokens=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ea4fb3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "input_ids = torch.tensor(input_ids).unsqueeze(0)  # Add batch dimension\n",
    "outputs = model(input_ids)\n",
    "last_hidden_states = outputs.last_hidden_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64510b7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: numpy in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (1.22.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install numpy\n",
    "import numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "821507e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pinecone-client in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (2.2.1)\n",
      "Requirement already satisfied: requests>=2.19.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (2.27.1)\n",
      "Requirement already satisfied: pyyaml>=5.4 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (5.4.1)\n",
      "Requirement already satisfied: loguru>=0.5.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (0.7.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (4.2.0)\n",
      "Requirement already satisfied: dnspython>=2.0.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (2.3.0)\n",
      "Requirement already satisfied: python-dateutil>=2.5.3 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (2.8.2)\n",
      "Requirement already satisfied: urllib3>=1.21.1 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (1.24.3)\n",
      "Requirement already satisfied: tqdm>=4.64.1 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (4.65.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from pinecone-client) (1.22.2)\n",
      "Requirement already satisfied: colorama>=0.3.4 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (0.4.4)\n",
      "Requirement already satisfied: win32-setctime>=1.0.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from loguru>=0.5.0->pinecone-client) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from python-dateutil>=2.5.3->pinecone-client) (1.12.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.0.12)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages (from requests>=2.19.0->pinecone-client) (2.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -pencv-python (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -rotobuf (c:\\users\\athar\\appdata\\local\\programs\\python\\python310\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "!pip install pinecone-client\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ca6af730",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "# Define your model\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)\n",
    "        self.fc2 = nn.Linear(5, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = torch.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Create an instance of your model\n",
    "model = MyModel()\n",
    "\n",
    "# Train your model\n",
    "\n",
    "# Save your model\n",
    "torch.save(model.state_dict(), 'model.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01aa973b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('tokenizer\\\\tokenizer_config.json',\n",
       " 'tokenizer\\\\special_tokens_map.json',\n",
       " 'tokenizer\\\\vocab.json',\n",
       " 'tokenizer\\\\merges.txt',\n",
       " 'tokenizer\\\\added_tokens.json')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# save the tokenizer\n",
    "import torch\n",
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "tokenizer.save_pretrained('tokenizer')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "40e66dc1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello, who are you?\n",
      "\n",
      "I'm a student at the University of California, Berkeley.\n"
     ]
    }
   ],
   "source": [
    "from transformers import GPT2Tokenizer, GPT2LMHeadModel\n",
    "\n",
    "# Load tokenizer from the Hugging Face model hub\n",
    "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
    "# Load tokenizer and model\n",
    "model_name = 'gpt2'\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
    "\n",
    "# Run inference\n",
    "input_text = \"Hello, who are you?\"\n",
    "inputs = tokenizer.encode(input_text, return_tensors='pt')\n",
    "output = model.generate(inputs)\n",
    "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
    "print(generated_text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "57ceccce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208f7209aca441e7aa3038a24015384b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Text(value='', description='Input:', placeholder='Type something')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dd81bab6dbfb480c93c540bce89ee613",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(button_style='info', description='Submit', style=ButtonStyle(), tooltip='Click to submit input text')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "import numpy as np\n",
    "import pinecone\n",
    "\n",
    "# Define a function to perform vectorization\n",
    "def vectorize(text):\n",
    "    # Connect to the Pinecone index\n",
    "    pinecone.init(api_key=\"6590d6c6-3fda-495c-946b-d288ead59c1d\", environment=\"asia-southeast1-gcp-free\")\n",
    "\n",
    "    # Get the Pinecone index\n",
    "    index = pinecone.Index(\"my-index\")\n",
    "\n",
    "    # Vectorize the text using the Pinecone index\n",
    "    #vectors = index.encode(text)\n",
    "    #return vectors\n",
    "    # Add the text to the index and retrieve the resulting vectors\n",
    "    vectors = index.encode(text)\n",
    "    \n",
    "    return vectors[0]\n",
    "\n",
    "# Create a text box widget for input text\n",
    "text_box = widgets.Text(\n",
    "    value='',\n",
    "    placeholder='Type something',\n",
    "    description='Input:',\n",
    "    disabled=False\n",
    ")\n",
    "\n",
    "# Create a button widget for submitting the input text\n",
    "button = widgets.Button(\n",
    "    description='Submit',\n",
    "    disabled=False,\n",
    "    button_style='info', # 'success', 'info', 'warning', 'danger' or ''\n",
    "    tooltip='Click to submit input text'\n",
    ")\n",
    "\n",
    "# Define a function to handle button click event\n",
    "def on_button_clicked(b):\n",
    "    # Get the input text\n",
    "    input_text = text_box.value\n",
    "\n",
    "    # Vectorize the input text\n",
    "    vectors = vectorize(input_text)\n",
    "\n",
    "    # Display the vectors\n",
    "    print(vectors)\n",
    "\n",
    "# Attach the button click event handler to the button\n",
    "button.on_click(on_button_clicked)\n",
    "\n",
    "# Display the text box and the button\n",
    "display(text_box)\n",
    "display(button)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a54b370a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
